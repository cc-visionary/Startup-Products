{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "import xlsxwriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding options\n",
    "\n",
    "chromeOptions = Options()\n",
    "chromeOptions.add_argument('--kiosk')\n",
    "chromeOptions.page_load_strategy = 'normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the webpage\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver/chromedriver', options=chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.producthunt.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Betalist listings\n",
    "### Steps:\n",
    "1. Scroll down the page\n",
    "2. Scrape the dates (for reference: to see which timeframe was scraped)\n",
    "3. Get all the cards\n",
    "4. Loop the cards then scrape all the necessary data(then add it into a list):\n",
    "    - Product Name\n",
    "    - Description\n",
    "    - Votes\n",
    "    - href (to get the Tags and URL since it doesn't exist in the home page)  \n",
    "5. Loop the list and go to each href then scrape the website to get the URL.\n",
    "6. Save the lists with complete information to an excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150): # scrolling down the page\n",
    "    print(i, driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(1) # give the browser some time to load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all dates (for reference as to when to when we got the dates.)\n",
    "get_all_date = driver.find_elements_by_class_name('startupDeckHeader')\n",
    "print(len(get_all_date))\n",
    "for date in get_all_date: \n",
    "    print(date.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = driver.find_elements_by_class_name('startupCard') # getting all cards from classname\n",
    "print(len(cards))\n",
    "listings = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, card in enumerate(cards):\n",
    "    try:\n",
    "        title = card.find_element_by_class_name('startupCard__details__name').text # getting title from its class\n",
    "        description = card.find_element_by_class_name('startupCard__details__pitch').text # getting description from its class \n",
    "        vote = card.find_element_by_class_name('cuteButton--upvote').find_element_by_class_name('cuteButton__score').find_element_by_tag_name('span').text # getting vote from classname then span\n",
    "        tag = card.find_element_by_class_name('startupCard__details__name').get_attribute('href') # getting tags from its class then span\n",
    "        href = card.find_element_by_tag_name('a').get_attribute('href') # get href through anchor tag's href attribute\n",
    "        listings.append({'product': title, 'description': description, 'tag': None, 'vote': vote, 'url': None, 'href': href})\n",
    "    except:\n",
    "        print('error', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(listings))\n",
    "for i in listings:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in products: # getting the websites\n",
    "    driver.get(i['href'])\n",
    "    i['url'] = driver.find_element_by_class_name('side_c0705').find_element_by_tag_name('span').text # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
